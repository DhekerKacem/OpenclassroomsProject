{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gwbSTJkl45Ow"
   },
   "source": [
    "### Réalisez une analyse de sentiments grâce au Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OTFOEyrI45Oy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fOvS8I3m45Oz"
   },
   "source": [
    "### Présentation du projet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p8o6ppXz45O0"
   },
   "source": [
    "La compagnie aérienne Air Paradis a missionné notre cabinet pour créer un produit IA permettant d’anticiper les bad buzz sur les réseaux sociaux.\n",
    "\n",
    "Air Paradis veut un prototype d’un produit IA permettant de prédire le sentiment associé à un tweet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NNgZipLQ45O0"
   },
   "source": [
    "### Importation des bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-04-15T21:45:33.579901Z",
     "iopub.status.busy": "2024-04-15T21:45:33.579494Z",
     "iopub.status.idle": "2024-04-15T21:45:53.118580Z",
     "shell.execute_reply": "2024-04-15T21:45:53.117455Z",
     "shell.execute_reply.started": "2024-04-15T21:45:33.579869Z"
    },
    "id": "iPYAeHV_45O0",
    "outputId": "8539f790-ead3-4536-ac57-3acdfa422e18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlflow\n",
      "  Downloading mlflow-2.12.1-py3-none-any.whl (20.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.2/20.2 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: Flask<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.5)\n",
      "Collecting alembic!=1.10.0,<2 (from mlflow)\n",
      "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.1)\n",
      "Collecting docker<8,>=4.0.0 (from mlflow)\n",
      "  Downloading docker-7.0.0-py3-none-any.whl (147 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.6/147.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: entrypoints<1 in /usr/local/lib/python3.10/dist-packages (from mlflow) (0.4)\n",
      "Collecting gitpython<4,>=3.1.9 (from mlflow)\n",
      "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting graphene<4 (from mlflow)\n",
      "  Downloading graphene-3.3-py2.py3-none-any.whl (128 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata!=4.7.0,<8,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (7.1.0)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.6)\n",
      "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.7.1)\n",
      "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.25.2)\n",
      "Requirement already satisfied: packaging<25 in /usr/local/lib/python3.10/dist-packages (from mlflow) (24.0)\n",
      "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.0.3)\n",
      "Requirement already satisfied: protobuf<6,>=3.12.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.20.3)\n",
      "Requirement already satisfied: pyarrow<16,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (14.0.2)\n",
      "Requirement already satisfied: pytz<2025 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2023.4)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.10/dist-packages (from mlflow) (6.0.1)\n",
      "Collecting querystring-parser<2 (from mlflow)\n",
      "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.31.0)\n",
      "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.2.2)\n",
      "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.11.4)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.0.29)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (0.4.4)\n",
      "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.1.3)\n",
      "Collecting gunicorn<22 (from mlflow)\n",
      "  Downloading gunicorn-21.2.0-py3-none-any.whl (80 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.2/80.2 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting Mako (from alembic!=1.10.0,<2->mlflow)\n",
      "  Downloading Mako-1.3.3-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic!=1.10.0,<2->mlflow) (4.11.0)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker<8,>=4.0.0->mlflow) (2.0.7)\n",
      "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (3.0.2)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (2.1.2)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython<4,>=3.1.9->mlflow)\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
      "  Downloading graphql_core-3.2.3-py3-none-any.whl (202 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.9/202.9 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
      "  Downloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
      "Collecting aniso8601<10,>=8 (from graphene<4->mlflow)\n",
      "  Downloading aniso8601-9.0.1-py2.py3-none-any.whl (52 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata!=4.7.0,<8,>=3.7.0->mlflow) (3.18.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2<4,>=2.11->mlflow) (2.1.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.4.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3->mlflow) (2024.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from querystring-parser<2->mlflow) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow) (2024.2.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (3.4.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.0.3)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow)\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: aniso8601, smmap, querystring-parser, Mako, gunicorn, graphql-core, graphql-relay, gitdb, docker, alembic, graphene, gitpython, mlflow\n",
      "Successfully installed Mako-1.3.3 alembic-1.13.1 aniso8601-9.0.1 docker-7.0.0 gitdb-4.0.11 gitpython-3.1.43 graphene-3.3 graphql-core-3.2.3 graphql-relay-3.2.0 gunicorn-21.2.0 mlflow-2.12.1 querystring-parser-1.2.4 smmap-5.0.1\n"
     ]
    }
   ],
   "source": [
    "pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-04-15T21:45:54.576020Z",
     "iopub.status.busy": "2024-04-15T21:45:54.575658Z",
     "iopub.status.idle": "2024-04-15T21:46:07.301049Z",
     "shell.execute_reply": "2024-04-15T21:46:07.299786Z",
     "shell.execute_reply.started": "2024-04-15T21:45:54.575989Z"
    },
    "id": "KrX7qJdU45O1",
    "outputId": "c0366d56-3909-4887-eb13-65e29cc452c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-04-15T21:46:23.699723Z",
     "iopub.status.busy": "2024-04-15T21:46:23.699329Z",
     "iopub.status.idle": "2024-04-15T21:46:40.475440Z",
     "shell.execute_reply": "2024-04-15T21:46:40.474370Z",
     "shell.execute_reply.started": "2024-04-15T21:46:23.699688Z"
    },
    "id": "LUuaWavv45O2",
    "outputId": "baf440aa-6959-47ac-bea0-266d632aaa74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.1)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-15T21:46:53.490473Z",
     "iopub.status.busy": "2024-04-15T21:46:53.490098Z",
     "iopub.status.idle": "2024-04-15T21:47:42.904863Z",
     "shell.execute_reply": "2024-04-15T21:47:42.904036Z",
     "shell.execute_reply.started": "2024-04-15T21:46:53.490440Z"
    },
    "id": "sjStxowL45O2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import defaultdict\n",
    "from torch import nn, optim\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import gensim\n",
    "import os\n",
    "from torch import nn, optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau  # Import de ReduceLROnPlateau\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, SpatialDropout1D, Bidirectional\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Dropout\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize, RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import scipy.sparse\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "import torch\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from transformers import BertTokenizer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VvykedClBOaq",
    "outputId": "255043bb-0b3d-4e53-b89b-eea1bfdbc1d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sw7A5-3X45O3"
   },
   "source": [
    "### Importer et explorer les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-15T21:47:46.899995Z",
     "iopub.status.busy": "2024-04-15T21:47:46.899154Z",
     "iopub.status.idle": "2024-04-15T21:47:50.932411Z",
     "shell.execute_reply": "2024-04-15T21:47:50.931227Z",
     "shell.execute_reply.started": "2024-04-15T21:47:46.899963Z"
    },
    "id": "typW8m3w45O3"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('/content/drive/My Drive/df_kaggle.csv', delimiter=',', skiprows=[5312], encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "execution": {
     "iopub.execute_input": "2024-04-15T21:47:58.566860Z",
     "iopub.status.busy": "2024-04-15T21:47:58.566034Z",
     "iopub.status.idle": "2024-04-15T21:47:58.583541Z",
     "shell.execute_reply": "2024-04-15T21:47:58.582318Z",
     "shell.execute_reply.started": "2024-04-15T21:47:58.566826Z"
    },
    "id": "yALAMdIa45O4",
    "outputId": "440ca18d-db98-4fa5-fbc4-23dd41ffeeef"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "data"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-af90bb4b-6951-4566-aca2-df603c6ce7e7\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-af90bb4b-6951-4566-aca2-df603c6ce7e7')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-af90bb4b-6951-4566-aca2-df603c6ce7e7 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-af90bb4b-6951-4566-aca2-df603c6ce7e7');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-d8a6c6c1-464f-4065-a4b2-ec6ec704926d\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d8a6c6c1-464f-4065-a4b2-ec6ec704926d')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-d8a6c6c1-464f-4065-a4b2-ec6ec704926d button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   Label                                               Text\n",
       "0      0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1      0  is upset that he can't update his Facebook by ...\n",
       "2      0  @Kenichan I dived many times for the ball. Man...\n",
       "3      0    my whole body feels itchy and like its on fire \n",
       "4      0  @nationwideclass no, it's not behaving at all...."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-04-15T21:48:01.486822Z",
     "iopub.status.busy": "2024-04-15T21:48:01.486443Z",
     "iopub.status.idle": "2024-04-15T21:48:01.702667Z",
     "shell.execute_reply": "2024-04-15T21:48:01.701699Z",
     "shell.execute_reply.started": "2024-04-15T21:48:01.486791Z"
    },
    "id": "22tAfx-N45O4",
    "outputId": "83955e63-bbf9-4ffe-d218-d5757eb82060"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1581338 entries, 0 to 1581337\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count    Dtype \n",
      "---  ------  --------------    ----- \n",
      " 0   Label   1581338 non-null  int64 \n",
      " 1   Text    1581338 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 24.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-04-15T21:48:03.618418Z",
     "iopub.status.busy": "2024-04-15T21:48:03.617724Z",
     "iopub.status.idle": "2024-04-15T21:48:04.520184Z",
     "shell.execute_reply": "2024-04-15T21:48:04.519215Z",
     "shell.execute_reply.started": "2024-04-15T21:48:03.618383Z"
    },
    "id": "wIqLZD0c45O4",
    "outputId": "9dff06de-c816-4b64-9b9c-591709442704"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label          2\n",
       "Text     1581338\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iO9LtXkc45O4"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-04-15T21:48:06.447253Z",
     "iopub.status.busy": "2024-04-15T21:48:06.446754Z",
     "iopub.status.idle": "2024-04-15T21:48:06.646725Z",
     "shell.execute_reply": "2024-04-15T21:48:06.645741Z",
     "shell.execute_reply.started": "2024-04-15T21:48:06.447217Z"
    },
    "id": "_s_-Jkyu45O5",
    "outputId": "14e5b8f4-62d4-4abc-ec78-87f5ce939ac3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label    0\n",
       "Text     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "execution": {
     "iopub.execute_input": "2024-04-15T21:48:08.274123Z",
     "iopub.status.busy": "2024-04-15T21:48:08.273215Z",
     "iopub.status.idle": "2024-04-15T21:48:08.331350Z",
     "shell.execute_reply": "2024-04-15T21:48:08.330376Z",
     "shell.execute_reply.started": "2024-04-15T21:48:08.274088Z"
    },
    "id": "1hAqUnbF45O5",
    "outputId": "66344d97-ad0a-4e46-b9fb-2840c483e1bf"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"data\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 559087.2095273406,\n        \"min\": 0.0,\n        \"max\": 1581338.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.5003225116957918,\n          1.0,\n          0.5000000540802051\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-ecc04260-11a9-4ca2-863d-08e1b418797e\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.581338e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.003225e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.000001e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ecc04260-11a9-4ca2-863d-08e1b418797e')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-ecc04260-11a9-4ca2-863d-08e1b418797e button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-ecc04260-11a9-4ca2-863d-08e1b418797e');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-11f07b86-c89a-4656-b9b5-81de541fa691\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-11f07b86-c89a-4656-b9b5-81de541fa691')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-11f07b86-c89a-4656-b9b5-81de541fa691 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "              Label\n",
       "count  1.581338e+06\n",
       "mean   5.003225e-01\n",
       "std    5.000001e-01\n",
       "min    0.000000e+00\n",
       "25%    0.000000e+00\n",
       "50%    1.000000e+00\n",
       "75%    1.000000e+00\n",
       "max    1.000000e+00"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kZQdKoNd45O5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lD7828jU45O5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A5FB7tRF45O5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "InyBIw9o45O5"
   },
   "source": [
    "### Bert pré entrainé"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1VABNotQ45O6"
   },
   "source": [
    "### Bert, Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-04-15T21:48:11.873927Z",
     "iopub.status.busy": "2024-04-15T21:48:11.873041Z",
     "iopub.status.idle": "2024-04-15T21:48:12.206233Z",
     "shell.execute_reply": "2024-04-15T21:48:12.205200Z",
     "shell.execute_reply.started": "2024-04-15T21:48:11.873893Z"
    },
    "id": "XTAJXtUa45O6",
    "outputId": "b1381177-f36e-4f1f-b4be-f57466317ec2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-15T21:48:14.186747Z",
     "iopub.status.busy": "2024-04-15T21:48:14.185914Z",
     "iopub.status.idle": "2024-04-15T21:48:14.190664Z",
     "shell.execute_reply": "2024-04-15T21:48:14.189710Z",
     "shell.execute_reply.started": "2024-04-15T21:48:14.186714Z"
    },
    "id": "XjmkTpIg45O6"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-04-15T21:48:16.405881Z",
     "iopub.status.busy": "2024-04-15T21:48:16.404924Z",
     "iopub.status.idle": "2024-04-15T21:48:17.496712Z",
     "shell.execute_reply": "2024-04-15T21:48:17.495566Z",
     "shell.execute_reply.started": "2024-04-15T21:48:16.405846Z"
    },
    "id": "eCgmRq-z45O6",
    "outputId": "b654b7db-1303-471b-8e64-c3991f0e8892"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Apr 17 14:57:55 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM4-40GB          Off | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   33C    P0              50W / 400W |      2MiB / 40960MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vJThQ4zY45O6"
   },
   "source": [
    "### Entrainement d'un premier modèle avec un échantillion de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oJpqUa-k45O6"
   },
   "source": [
    "### Modèle avec Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-04-15T21:48:19.902555Z",
     "iopub.status.busy": "2024-04-15T21:48:19.902047Z",
     "iopub.status.idle": "2024-04-15T21:48:20.426828Z",
     "shell.execute_reply": "2024-04-15T21:48:20.425873Z",
     "shell.execute_reply.started": "2024-04-15T21:48:19.902512Z"
    },
    "id": "30OuuLWw45O6",
    "outputId": "66f60777-2757-4b18-ba89-1833ac7a9c8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 600000 entries, 0 to 599999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   Label   600000 non-null  int64 \n",
      " 1   Text    600000 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 9.2+ MB\n",
      "None\n",
      "Taille de la base de données de test : (20000, 2)\n",
      "Taille de la base de données finale : (500000, 2)\n",
      "Distribution de la variable Label dans df_balanced_test:\n",
      "Label\n",
      "0    10017\n",
      "1     9983\n",
      "Name: count, dtype: int64\n",
      "Distribution de la variable Label dans df_balanced_final:\n",
      "Label\n",
      "1    250021\n",
      "0    249979\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Déterminer le nombre d'observations à sélectionner dans chaque classe\n",
    "num_samples_per_class = 300000\n",
    "\n",
    "# Diviser le dataframe en deux parties selon les labels\n",
    "df_label_0 = data[data['Label'] == 0]\n",
    "df_label_1 = data[data['Label'] == 1]\n",
    "\n",
    "# Sous-échantillonner chaque classe pour obtenir le nombre souhaité d'observations\n",
    "df_label_0 = df_label_0.sample(n=num_samples_per_class, random_state=42)\n",
    "df_label_1 = df_label_1.sample(n=num_samples_per_class, random_state=42)\n",
    "\n",
    "# Concaténer les deux parties pour former un nouvel ensemble de données équilibré\n",
    "df_balanced = pd.concat([df_label_0, df_label_1])\n",
    "\n",
    "# Mélanger les données\n",
    "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Afficher les informations sur le DataFrame équilibré\n",
    "print(df_balanced.info())\n",
    "\n",
    "# Sélectionner les 40 000 premières observations\n",
    "df_balanced_test = df_balanced.head(20000)\n",
    "df_balanced_final =  df_balanced.head(500000)\n",
    "\n",
    "# Afficher la taille des deux base de test et finale\n",
    "print(\"Taille de la base de données de test :\", df_balanced_test.shape)\n",
    "print(\"Taille de la base de données finale :\", df_balanced_final.shape)\n",
    "\n",
    "# Calcul des fréquences des valeurs de la variable cible et tri par ordre décroissant\n",
    "print(\"Distribution de la variable Label dans df_balanced_test:\")\n",
    "print(df_balanced_test['Label'].value_counts().sort_values(ascending=False))\n",
    "\n",
    "print(\"Distribution de la variable Label dans df_balanced_final:\")\n",
    "print(df_balanced_final['Label'].value_counts().sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Al72miPk45O7"
   },
   "source": [
    "### Avec gel du modèle BERT pré-entrainé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-04-15T21:50:45.721828Z",
     "iopub.status.busy": "2024-04-15T21:50:45.721479Z",
     "iopub.status.idle": "2024-04-15T22:25:43.650723Z",
     "shell.execute_reply": "2024-04-15T22:25:43.649655Z",
     "shell.execute_reply.started": "2024-04-15T21:50:45.721802Z"
    },
    "id": "MZrD6jl745O8",
    "outputId": "5082e1a4-9b92-4a4d-ae43-301ba9f5db23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le modèle a 769 paramètres à entraîner\n",
      "Epoch 1/10\n",
      "Train loss 0.6942989304065704 accuracy 0.5280625\n",
      "Val loss 0.6823889117240906 accuracy 0.5855\n",
      "Best model saved with accuracy: tensor(0.5855, device='cuda:0', dtype=torch.float64)\n",
      "Epoch 2/10\n",
      "Train loss 0.6939999147057533 accuracy 0.5299375000000001\n",
      "Val loss 0.6786454081535339 accuracy 0.5945\n",
      "Best model saved with accuracy: tensor(0.5945, device='cuda:0', dtype=torch.float64)\n",
      "Epoch 3/10\n",
      "Train loss 0.6865101940631867 accuracy 0.552625\n",
      "Val loss 0.6758310317993164 accuracy 0.6015\n",
      "Best model saved with accuracy: tensor(0.6015, device='cuda:0', dtype=torch.float64)\n",
      "Epoch 4/10\n",
      "Train loss 0.6852405787110328 accuracy 0.5498125\n",
      "Val loss 0.6736186800003052 accuracy 0.608\n",
      "Best model saved with accuracy: tensor(0.6080, device='cuda:0', dtype=torch.float64)\n",
      "Epoch 5/10\n",
      "Train loss 0.6857095863223076 accuracy 0.5504375\n",
      "Val loss 0.6717631516456604 accuracy 0.612\n",
      "Best model saved with accuracy: tensor(0.6120, device='cuda:0', dtype=torch.float64)\n",
      "Epoch 6/10\n",
      "Train loss 0.6848675163388253 accuracy 0.5513750000000001\n",
      "Val loss 0.6702191305160522 accuracy 0.6115\n",
      "Epoch 7/10\n",
      "Train loss 0.6826053087115288 accuracy 0.5606875\n",
      "Val loss 0.6691908168792725 accuracy 0.6165\n",
      "Best model saved with accuracy: tensor(0.6165, device='cuda:0', dtype=torch.float64)\n",
      "Epoch 8/10\n",
      "Train loss 0.6805612778663636 accuracy 0.5604375\n",
      "Val loss 0.668563886642456 accuracy 0.618\n",
      "Best model saved with accuracy: tensor(0.6180, device='cuda:0', dtype=torch.float64)\n",
      "Epoch 9/10\n",
      "Train loss 0.6776120292544365 accuracy 0.57175\n",
      "Val loss 0.6680323610305786 accuracy 0.619\n",
      "Best model saved with accuracy: tensor(0.6190, device='cuda:0', dtype=torch.float64)\n",
      "Epoch 10/10\n",
      "Train loss 0.6799114377498626 accuracy 0.5620625\n",
      "Val loss 0.6678803200721741 accuracy 0.6195\n",
      "Best model saved with accuracy: tensor(0.6195, device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Définition du modèle BERT à utiliser\n",
    "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'\n",
    "\n",
    "# Chargement du tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "\n",
    "# Longueur maximale des séquences\n",
    "MAX_LEN = 200\n",
    "\n",
    "# Classe Dataset pour traiter les données\n",
    "class GPReviewDataset(Dataset):\n",
    "    def __init__(self, reviews, targets, tokenizer, max_len):\n",
    "        self.reviews = reviews\n",
    "        self.targets = targets\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.reviews)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        review = str(self.reviews[item])\n",
    "        target = self.targets[item]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            review,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'targets': torch.tensor(target, dtype=torch.float)\n",
    "        }\n",
    "\n",
    "# Séparation des données en ensembles d'entraînement, de validation et de test\n",
    "df_train, df_test = train_test_split(df_balanced_test, test_size=0.2, random_state=42)\n",
    "df_val, df_test = train_test_split(df_test, test_size=0.5, random_state=42)\n",
    "\n",
    "# Création des DataLoaders\n",
    "BATCH_SIZE = 16\n",
    "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
    "    ds = GPReviewDataset(\n",
    "        reviews=df['Text'].to_numpy(),\n",
    "        targets=df['Label'].to_numpy(),\n",
    "        tokenizer=tokenizer,\n",
    "        max_len=max_len\n",
    "    )\n",
    "    return DataLoader(ds, batch_size=batch_size)\n",
    "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "\n",
    "\n",
    "# Définition du modèle de classification\n",
    "class SentimentClassifier(nn.Module):\n",
    "    def __init__(self, PRE_TRAINED_MODEL_NAME, freeze_bert=False):\n",
    "        super(SentimentClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "        self.drop = nn.Dropout(p=0.3)\n",
    "        self.out = nn.Linear(self.bert.config.hidden_size, 1)\n",
    "\n",
    "        if freeze_bert:\n",
    "            for param in self.bert.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        output = self.drop(outputs.pooler_output)\n",
    "        return self.out(output).squeeze(-1)\n",
    "\n",
    "# Configuration de l'appareil et du modèle\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_test = SentimentClassifier(PRE_TRAINED_MODEL_NAME, freeze_bert=True)\n",
    "model_test = model_test.to(device)\n",
    "\n",
    "# Nombre de paramètres à entraîner\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'Le modèle a {count_parameters(model_test):,} paramètres à entraîner')\n",
    "\n",
    "# Définition de l'optimiseur, du scheduler et de la fonction de perte\n",
    "EPOCHS = 10\n",
    "optimizer = AdamW(model_test.parameters(), lr=2e-5, correct_bias=False)\n",
    "total_steps = len(train_data_loader) * EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "loss_fn = nn.BCEWithLogitsLoss().to(device)\n",
    "\n",
    "# Fonctions d'entraînement et d'évaluation\n",
    "def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    for d in data_loader:\n",
    "        input_ids = d[\"input_ids\"].to(device)\n",
    "        attention_mask = d[\"attention_mask\"].to(device)\n",
    "        targets = d[\"targets\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        preds = torch.round(torch.sigmoid(outputs))\n",
    "        correct_predictions += torch.sum(preds == targets)\n",
    "\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)\n",
    "\n",
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    with torch.no_grad():\n",
    "        for d in data_loader:\n",
    "            input_ids = d[\"input_ids\"].to(device)\n",
    "            attention_mask = d[\"attention_mask\"].to(device)\n",
    "            targets = d[\"targets\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids.squeeze(), attention_mask=attention_mask.squeeze())\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            losses.append(loss.item())\n",
    "            preds = torch.round(torch.sigmoid(outputs)).squeeze()\n",
    "            correct_predictions += torch.sum(preds == targets)\n",
    "\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)\n",
    "\n",
    "# Définition du chemin de sauvegarde sur Kaggle\n",
    "save_dir = '/kaggle/test/working'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# Entraînement avec arrêt précoce\n",
    "best_accuracy = 0\n",
    "counter = 0\n",
    "patience = 3\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n",
    "    train_acc, train_loss = train_epoch(\n",
    "        model_test, train_data_loader, loss_fn, optimizer, device, scheduler, len(df_train)\n",
    "    )\n",
    "    print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "\n",
    "    val_acc, val_loss = eval_model(\n",
    "        model_test, val_data_loader, loss_fn, device, len(df_val)\n",
    "    )\n",
    "    print(f'Val loss {val_loss} accuracy {val_acc}')\n",
    "\n",
    "    if val_acc > best_accuracy:\n",
    "        best_accuracy = val_acc\n",
    "        counter = 0\n",
    "        best_model_path = os.path.join(save_dir, 'bert_model_best.bin')\n",
    "        torch.save(model_test.state_dict(), best_model_path)\n",
    "        print(\"Best model saved with accuracy:\", best_accuracy)\n",
    "    else:\n",
    "        counter += 1\n",
    "\n",
    "    if counter >= patience:\n",
    "        print(\"Early stopping triggered!\")\n",
    "        last_model_path = os.path.join(save_dir, 'bert_model_last.bin')\n",
    "        if val_acc != best_accuracy:  # Ensure to save last model if it's not the best\n",
    "            torch.save(model_test.state_dict(), last_model_path)\n",
    "            print(\"Last model state saved before stopping.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0k2QYk6f45O9"
   },
   "source": [
    "### Sans gel du modèle BERT pré-entrainé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5nimubNeLv36",
    "outputId": "a31c7291-ad67-43e2-aab3-8aa1c8b9b4e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "# Définition du chemin de sauvegarde sur Google Drive\n",
    "save_directory_test = '/content/drive/My Drive/Colab Models test'\n",
    "\n",
    "import os\n",
    "if not os.path.exists(save_directory_test):\n",
    "    os.makedirs(save_directory_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-04-15T22:26:54.883497Z",
     "iopub.status.busy": "2024-04-15T22:26:54.883130Z",
     "iopub.status.idle": "2024-04-15T23:11:24.622008Z",
     "shell.execute_reply": "2024-04-15T23:11:24.620947Z",
     "shell.execute_reply.started": "2024-04-15T22:26:54.883470Z"
    },
    "id": "WUxc0RkL45O9",
    "outputId": "b85d9db7-9aa4-4d0b-d44a-f5e81f7613ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le modèle a 108,311,041 paramètres à entraîner\n",
      "Epoch 1/5\n",
      "Train loss 0.5144911636263132 accuracy 0.7455\n",
      "Val loss 0.3983567134141922 accuracy 0.8195\n",
      "Best model saved with accuracy: tensor(0.8195, device='cuda:0', dtype=torch.float64)\n",
      "Epoch 2/5\n",
      "Train loss 0.3501617063358426 accuracy 0.855625\n",
      "Val loss 0.4289523103833199 accuracy 0.8245\n",
      "Best model saved with accuracy: tensor(0.8245, device='cuda:0', dtype=torch.float64)\n",
      "Epoch 3/5\n",
      "Train loss 0.2346795699847862 accuracy 0.9185625000000001\n",
      "Val loss 0.5212874783277511 accuracy 0.8270000000000001\n",
      "Best model saved with accuracy: tensor(0.8270, device='cuda:0', dtype=torch.float64)\n",
      "Epoch 4/5\n",
      "Train loss 0.16833560051675886 accuracy 0.9530625\n",
      "Val loss 0.6997864347994327 accuracy 0.8205\n",
      "Epoch 5/5\n",
      "Train loss 0.12328065512422472 accuracy 0.968375\n",
      "Val loss 0.8044396907389164 accuracy 0.8195\n"
     ]
    }
   ],
   "source": [
    "# Définition du modèle BERT à utiliser\n",
    "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'\n",
    "\n",
    "# Chargement du tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "\n",
    "# Spécifiez le répertoire où vous voulez sauvegarder le tokenizer\n",
    "tokenizer.save_pretrained(save_directory_test)\n",
    "\n",
    "# Longueur maximale des séquences\n",
    "MAX_LEN = 200\n",
    "\n",
    "# Classe Dataset pour traiter les données\n",
    "class GPReviewDataset(Dataset):\n",
    "    def __init__(self, reviews, targets, tokenizer, max_len):\n",
    "        self.reviews = reviews\n",
    "        self.targets = targets\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.reviews)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        review = str(self.reviews[item])\n",
    "        target = self.targets[item]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            review,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'targets': torch.tensor(target, dtype=torch.float)\n",
    "        }\n",
    "\n",
    "# Séparation des données en ensembles d'entraînement, de validation et de test\n",
    "df_train, df_test = train_test_split(df_balanced_test, test_size=0.2, random_state=42)\n",
    "df_val, df_test = train_test_split(df_test, test_size=0.5, random_state=42)\n",
    "\n",
    "# Création des DataLoaders\n",
    "BATCH_SIZE = 16\n",
    "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
    "    ds = GPReviewDataset(\n",
    "        reviews=df['Text'].to_numpy(),\n",
    "        targets=df['Label'].to_numpy(),\n",
    "        tokenizer=tokenizer,\n",
    "        max_len=max_len\n",
    "    )\n",
    "    return DataLoader(ds, batch_size=batch_size)\n",
    "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "\n",
    "# Définition du modèle de classification\n",
    "class SentimentClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SentimentClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "        self.drop = nn.Dropout(p=0.3)\n",
    "        self.out = nn.Linear(self.bert.config.hidden_size, 1)\n",
    "\n",
    "        # Sauvegarde de la configuration du modèle dans le répertoire de travail sur Google Drive\n",
    "        self.config_path = os.path.join(save_directory_test, 'config.json')\n",
    "        self.bert.config.save_pretrained(save_directory_test)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        output = self.drop(outputs.pooler_output)\n",
    "        return self.out(output).squeeze(-1)\n",
    "\n",
    "# Configuration de l'appareil et du modèle\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_test_sans_gel = SentimentClassifier()\n",
    "model_test_sans_gel = model_test_sans_gel.to(device)\n",
    "\n",
    "# Nombre de paramètres à entraîner\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'Le modèle a {count_parameters(model_test_sans_gel):,} paramètres à entraîner')\n",
    "\n",
    "# Définition de l'optimiseur, du scheduler et de la fonction de perte\n",
    "EPOCHS = 5\n",
    "optimizer = AdamW(model_test_sans_gel.parameters(), lr=2e-5, correct_bias=False)\n",
    "total_steps = len(train_data_loader) * EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "loss_fn = nn.BCEWithLogitsLoss().to(device)\n",
    "\n",
    "# Fonctions d'entraînement et d'évaluation\n",
    "def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    for d in data_loader:\n",
    "        input_ids = d[\"input_ids\"].to(device)\n",
    "        attention_mask = d[\"attention_mask\"].to(device)\n",
    "        targets = d[\"targets\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        preds = torch.round(torch.sigmoid(outputs))\n",
    "        correct_predictions += torch.sum(preds == targets)\n",
    "\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)\n",
    "\n",
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    with torch.no_grad():\n",
    "        for d in data_loader:\n",
    "            input_ids = d[\"input_ids\"].to(device)\n",
    "            attention_mask = d[\"attention_mask\"].to(device)\n",
    "            targets = d[\"targets\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids.squeeze(), attention_mask=attention_mask.squeeze())\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            losses.append(loss.item())\n",
    "            preds = torch.round(torch.sigmoid(outputs)).squeeze()\n",
    "            correct_predictions += torch.sum(preds == targets)\n",
    "\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)\n",
    "\n",
    "# Entraînement avec arrêt précoce\n",
    "best_accuracy = 0\n",
    "counter = 0\n",
    "patience = 3\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n",
    "    train_acc, train_loss = train_epoch(\n",
    "        model_test_sans_gel, train_data_loader, loss_fn, optimizer, device, scheduler, len(df_train)\n",
    "    )\n",
    "    print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "\n",
    "    val_acc, val_loss = eval_model(\n",
    "        model_test_sans_gel, val_data_loader, loss_fn, device, len(df_val)\n",
    "    )\n",
    "    print(f'Val loss {val_loss} accuracy {val_acc}')\n",
    "\n",
    "    if val_acc > best_accuracy:\n",
    "        best_accuracy = val_acc\n",
    "        counter = 0\n",
    "        best_model_path = os.path.join(save_directory_test, 'bert_model_best_sans_gel.bin')\n",
    "        torch.save(model_test_sans_gel.state_dict(), best_model_path)\n",
    "        print(\"Best model saved with accuracy:\", best_accuracy)\n",
    "    else:\n",
    "        counter += 1\n",
    "\n",
    "    if counter >= patience:\n",
    "        print(\"Early stopping triggered!\")\n",
    "        last_model_path = os.path.join(save_directory_test, 'bert_model_last_sans_gel.bin')\n",
    "        if val_acc != best_accuracy:  # Ensure to save last model if it's not the best\n",
    "            torch.save(model_test_sans_gel.state_dict(), last_model_path)\n",
    "            print(\"Last model state saved before stopping.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O-6wfNwd8I06"
   },
   "source": [
    "Le modèle retenu est le modèle \"model_test\" car il fournit de meilleurs résultats et évite l'overfitting.\n",
    "L'objectif maintenant est de l'entrainer sur une plus grande partie des données pour plus de robustesse. Mon choix est de l'entrainer sur 500k données car au delà cela pose un probléme de temmps de clacul même en achetant des unités de calculs permettant d'utiliser des GPU plus puissants(V100 et A100)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7edxhVao45PH"
   },
   "source": [
    "### Libérer de la mémoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-04-15T23:15:49.302013Z",
     "iopub.status.busy": "2024-04-15T23:15:49.301098Z",
     "iopub.status.idle": "2024-04-15T23:15:49.738397Z",
     "shell.execute_reply": "2024-04-15T23:15:49.737460Z",
     "shell.execute_reply.started": "2024-04-15T23:15:49.301980Z"
    },
    "id": "0nKQAd8745PI",
    "outputId": "e3e08331-f6da-4624-a0db-4b961df2da2a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T17:00:07.707113Z",
     "iopub.status.busy": "2024-04-14T17:00:07.706743Z",
     "iopub.status.idle": "2024-04-14T17:00:07.778282Z",
     "shell.execute_reply": "2024-04-14T17:00:07.777302Z",
     "shell.execute_reply.started": "2024-04-14T17:00:07.707082Z"
    },
    "id": "YEfaGzE745PI"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-04-14T17:00:09.106662Z",
     "iopub.status.busy": "2024-04-14T17:00:09.106224Z",
     "iopub.status.idle": "2024-04-14T17:00:10.210521Z",
     "shell.execute_reply": "2024-04-14T17:00:10.209484Z",
     "shell.execute_reply.started": "2024-04-14T17:00:09.106618Z"
    },
    "id": "A0_MohjE45PI",
    "outputId": "ab868eee-68df-4332-ef3b-a2681a59d89b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Apr 17 15:24:59 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM4-40GB          Off | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   36C    P0              58W / 400W |   3707MiB / 40960MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9IUl9jcb45PI"
   },
   "source": [
    "### Entrainement du modèle avec l'ensemble des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zOYTAWYGHBAZ",
    "outputId": "138c7e7a-2df3-4f21-ff5e-00cfc731955c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "# Définition du chemin de sauvegarde sur Google Drive\n",
    "save_directory = '/content/drive/My Drive/Colab Models'\n",
    "\n",
    "import os\n",
    "if not os.path.exists(save_directory):\n",
    "    os.makedirs(save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-04-15T23:16:36.486382Z",
     "iopub.status.busy": "2024-04-15T23:16:36.485573Z",
     "iopub.status.idle": "2024-04-16T06:32:48.970780Z",
     "shell.execute_reply": "2024-04-16T06:32:48.969560Z",
     "shell.execute_reply.started": "2024-04-15T23:16:36.486336Z"
    },
    "id": "DqWOOmxG45PI",
    "outputId": "2a14ed06-89d2-479f-accf-b1e0c51c907c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le modèle a 769 paramètres à entraîner\n",
      "Epoch 1/5\n",
      "Train loss 0.6650820820379257 accuracy 0.5949850000000001\n",
      "Val loss 0.6323787490463257 accuracy 0.67696\n",
      "Best model saved with accuracy: tensor(0.6770, device='cuda:0', dtype=torch.float64)\n",
      "Epoch 2/5\n",
      "Train loss 0.6362748848056793 accuracy 0.6429450000000001\n",
      "Val loss 0.6130142720985413 accuracy 0.69054\n",
      "Best model saved with accuracy: tensor(0.6905, device='cuda:0', dtype=torch.float64)\n",
      "Epoch 3/5\n",
      "Train loss 0.6256007359969616 accuracy 0.6548375000000001\n",
      "Val loss 0.603353365764618 accuracy 0.69842\n",
      "Best model saved with accuracy: tensor(0.6984, device='cuda:0', dtype=torch.float64)\n",
      "Epoch 4/5\n",
      "Train loss 0.6203435582184792 accuracy 0.6584525000000001\n",
      "Val loss 0.5987839398670196 accuracy 0.70096\n",
      "Best model saved with accuracy: tensor(0.7010, device='cuda:0', dtype=torch.float64)\n",
      "Epoch 5/5\n",
      "Train loss 0.6187171956133842 accuracy 0.660945\n",
      "Val loss 0.5974936360740661 accuracy 0.70186\n",
      "Best model saved with accuracy: tensor(0.7019, device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Définition du modèle BERT à utiliser\n",
    "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'\n",
    "\n",
    "# Chargement du tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "\n",
    "# Spécifiez le répertoire où vous voulez sauvegarder le tokenizer\n",
    "tokenizer.save_pretrained(save_directory)\n",
    "\n",
    "# Longueur maximale des séquences\n",
    "MAX_LEN = 200\n",
    "\n",
    "# Classe Dataset pour traiter les données\n",
    "class GPReviewDataset(Dataset):\n",
    "    def __init__(self, reviews, targets, tokenizer, max_len):\n",
    "        self.reviews = reviews\n",
    "        self.targets = targets\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.reviews)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        review = str(self.reviews[item])\n",
    "        target = self.targets[item]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            review,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'targets': torch.tensor(target, dtype=torch.float)\n",
    "        }\n",
    "\n",
    "# Séparation des données en ensembles d'entraînement, de validation et de test\n",
    "df_train, df_test = train_test_split(df_balanced_final, test_size=0.2, random_state=42)\n",
    "df_val, df_test = train_test_split(df_test, test_size=0.5, random_state=42)\n",
    "\n",
    "# Création des DataLoaders\n",
    "BATCH_SIZE = 16\n",
    "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
    "    ds = GPReviewDataset(\n",
    "        reviews=df['Text'].to_numpy(),\n",
    "        targets=df['Label'].to_numpy(),\n",
    "        tokenizer=tokenizer,\n",
    "        max_len=max_len\n",
    "    )\n",
    "    return DataLoader(ds, batch_size=batch_size)\n",
    "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "\n",
    "\n",
    "# Définition du modèle de classification\n",
    "class SentimentClassifier(nn.Module):\n",
    "    def __init__(self, PRE_TRAINED_MODEL_NAME, freeze_bert=False):\n",
    "        super(SentimentClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "        self.drop = nn.Dropout(p=0.3)\n",
    "        self.out = nn.Linear(self.bert.config.hidden_size, 1)\n",
    "\n",
    "        # Sauvegarde de la configuration du modèle dans le répertoire de travail sur Google Drive\n",
    "        self.config_path = os.path.join(save_directory, 'config.json')\n",
    "        self.bert.config.save_pretrained(save_directory)\n",
    "\n",
    "        if freeze_bert:\n",
    "            for param in self.bert.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        output = self.drop(outputs.pooler_output)\n",
    "        return self.out(output).squeeze(-1)\n",
    "\n",
    "# Configuration de l'appareil et du modèle\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_final = SentimentClassifier(PRE_TRAINED_MODEL_NAME, freeze_bert=True)\n",
    "model_final = model_final.to(device)\n",
    "\n",
    "# Nombre de paramètres à entraîner\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'Le modèle a {count_parameters(model_final):,} paramètres à entraîner')\n",
    "\n",
    "# Définition de l'optimiseur, du scheduler et de la fonction de perte\n",
    "EPOCHS = 5\n",
    "optimizer = AdamW(model_final.parameters(), lr=2e-5, correct_bias=False)\n",
    "total_steps = len(train_data_loader) * EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "loss_fn = nn.BCEWithLogitsLoss().to(device)\n",
    "\n",
    "# Fonctions d'entraînement et d'évaluation\n",
    "def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    for d in data_loader:\n",
    "        input_ids = d[\"input_ids\"].to(device)\n",
    "        attention_mask = d[\"attention_mask\"].to(device)\n",
    "        targets = d[\"targets\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        preds = torch.round(torch.sigmoid(outputs))\n",
    "        correct_predictions += torch.sum(preds == targets)\n",
    "\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)\n",
    "\n",
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    with torch.no_grad():\n",
    "        for d in data_loader:\n",
    "            input_ids = d[\"input_ids\"].to(device)\n",
    "            attention_mask = d[\"attention_mask\"].to(device)\n",
    "            targets = d[\"targets\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids.squeeze(), attention_mask=attention_mask.squeeze())\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            losses.append(loss.item())\n",
    "            preds = torch.round(torch.sigmoid(outputs)).squeeze()\n",
    "            correct_predictions += torch.sum(preds == targets)\n",
    "\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)\n",
    "\n",
    "\n",
    "# Entraînement avec arrêt précoce\n",
    "best_accuracy = 0\n",
    "counter = 0\n",
    "patience = 2\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n",
    "    train_acc, train_loss = train_epoch(\n",
    "        model_final, train_data_loader, loss_fn, optimizer, device, scheduler, len(df_train)\n",
    "    )\n",
    "    print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "\n",
    "    val_acc, val_loss = eval_model(\n",
    "        model_final, val_data_loader, loss_fn, device, len(df_val)\n",
    "    )\n",
    "    print(f'Val loss {val_loss} accuracy {val_acc}')\n",
    "\n",
    "    if val_acc > best_accuracy:\n",
    "        best_accuracy = val_acc\n",
    "        counter = 0\n",
    "        best_model_path = os.path.join(save_directory, 'bert_model_best_final.bin')\n",
    "        torch.save(model_final.state_dict(), best_model_path)\n",
    "        print(\"Best model saved with accuracy:\", best_accuracy)\n",
    "    else:\n",
    "        counter += 1\n",
    "\n",
    "    if counter >= patience:\n",
    "        print(\"Early stopping triggered!\")\n",
    "        last_model_path = os.path.join(save_directory, 'bert_model_last_final.bin')\n",
    "        if val_acc != best_accuracy:  # Ensure to save last model if it's not the best\n",
    "            torch.save(model_final.state_dict(), last_model_path)\n",
    "            print(\"Last model state saved before stopping.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DOY3TMpl769s"
   },
   "source": [
    "### Test du modèle finale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L3kyxloGVRNV",
    "outputId": "ebc39417-da72-415e-955f-05633f28270f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test   loss 0.5983138734436035 accuracy 0.7012200000000001\n"
     ]
    }
   ],
   "source": [
    "# Evaluation du modèle sur l'ensemble de test\n",
    "test_acc, test_loss = eval_model(\n",
    "    model_final,\n",
    "    test_data_loader,\n",
    "    loss_fn,\n",
    "    device,\n",
    "    len(df_test)\n",
    ")\n",
    "\n",
    "print(f'Test   loss {test_loss} accuracy {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zx1pN6M7XaiP"
   },
   "outputs": [],
   "source": [
    "def test_tweets(model, tokenizer, tweets, device, max_len=200):\n",
    "    model.eval()  # Met le modèle en mode évaluation\n",
    "    for tweet in tweets:\n",
    "        encoded_input = tokenizer.encode_plus(\n",
    "            tweet,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        input_ids = encoded_input['input_ids'].to(device)\n",
    "        attention_mask = encoded_input['attention_mask'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(input_ids, attention_mask)\n",
    "            prediction = torch.sigmoid(output).item()  # Assumant que le modèle retourne un score de logit pour la classification binaire\n",
    "\n",
    "        print(f\"Tweet: '{tweet}'\")\n",
    "        print(f\"Sentiment: {'Positive' if prediction >= 0.5 else 'Negative'}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TZs1YUTs45PK",
    "outputId": "11795002-d4d4-4f02-f2da-f5e647021e87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: 'I absolutely loved this new movie, it was really great!'\n",
      "Sentiment: Positive\n",
      "\n",
      "Tweet: 'This restaurant was horrible, the service was very slow, and the food was cold.'\n",
      "Sentiment: Negative\n",
      "\n",
      "Tweet: 'The new smartphone from this brand is amazing, with an excellent camera and long battery life.'\n",
      "Sentiment: Positive\n",
      "\n",
      "Tweet: 'I'm very disappointed with this product, it doesn't work as advertised.'\n",
      "Sentiment: Negative\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Charger le modèle entraîné\n",
    "model_final = SentimentClassifier(PRE_TRAINED_MODEL_NAME, freeze_bert=True)\n",
    "model_path = '/content/drive/My Drive/Colab Models/bert_model_best_final.bin'\n",
    "model_final.load_state_dict(torch.load(model_path))\n",
    "model_final = model_final.to(device)\n",
    "\n",
    "# Charger le tokenizer BERT\n",
    "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "\n",
    "# Définir la longueur maximale des séquences\n",
    "MAX_LEN = 200\n",
    "\n",
    "# Exemple de tweets en anglais à tester\n",
    "tweets_à_tester = [\n",
    "    \"I absolutely loved this new movie, it was really great!\",\n",
    "    \"This restaurant was horrible, the service was very slow, and the food was cold.\",\n",
    "    \"The new smartphone from this brand is amazing, with an excellent camera and long battery life.\",\n",
    "    \"I'm very disappointed with this product, it doesn't work as advertised.\"\n",
    "]\n",
    "\n",
    "# Tester les tweets\n",
    "test_tweets(model_final, tokenizer, tweets_à_tester, device)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4712015,
     "sourceId": 8001606,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4717623,
     "sourceId": 8009478,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4721088,
     "sourceId": 8013506,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4752869,
     "sourceId": 8058024,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30674,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
